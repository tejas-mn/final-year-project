{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd364a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of contours detected: 12\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import cv2 # Computer vision library\n",
    " \n",
    "# Read the color image\n",
    "image = cv2.imread(\"s1.jpg\")\n",
    " \n",
    "# Make a copy\n",
    "new_image = image.copy()\n",
    " \n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Display the grayscale image\n",
    "cv2.imshow('Gray image', gray)  \n",
    "cv2.waitKey(0) # Wait for keypress to continue\n",
    "cv2.destroyAllWindows() # Close windows\n",
    " \n",
    "# Convert the grayscale image to binary\n",
    "ret, binary = cv2.threshold(gray, 100, 255, \n",
    "  cv2.THRESH_OTSU)\n",
    " \n",
    "# Display the binary image\n",
    "cv2.imshow('Binary image', binary)\n",
    "cv2.waitKey(0) # Wait for keypress to continue\n",
    "cv2.destroyAllWindows() # Close windows\n",
    " \n",
    "# To detect object contours, we want a black background and a white \n",
    "# foreground, so we invert the image (i.e. 255 - pixel value)\n",
    "inverted_binary = ~binary\n",
    "cv2.imshow('Inverted binary image', inverted_binary)\n",
    "cv2.waitKey(0) # Wait for keypress to continue\n",
    "cv2.destroyAllWindows() # Close windows\n",
    " \n",
    "# Find the contours on the inverted binary image, and store them in a list\n",
    "# Contours are drawn around white blobs.\n",
    "# hierarchy variable contains info on the relationship between the contours\n",
    "contours, hierarchy = cv2.findContours(inverted_binary,\n",
    "  cv2.RETR_TREE,\n",
    "  cv2.CHAIN_APPROX_SIMPLE)\n",
    "     \n",
    "# Draw the contours (in red) on the original image and display the result\n",
    "# Input color code is in BGR (blue, green, red) format\n",
    "# -1 means to draw all contours\n",
    "with_contours = cv2.drawContours(image, contours, -1,(255,0,255),3)\n",
    "cv2.imshow('Detected contours', with_contours)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Show the total number of contours that were detected\n",
    "print('Total number of contours detected: ' + str(len(contours)))\n",
    " \n",
    "# Draw just the first contour\n",
    "# The 0 means to draw the first contour\n",
    "first_contour = cv2.drawContours(new_image, contours, 0,(255,0,255),3)\n",
    "cv2.imshow('First detected contour', first_contour)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Draw a bounding box around the first contour\n",
    "# x is the starting x coordinate of the bounding box\n",
    "# y is the starting y coordinate of the bounding box\n",
    "# w is the width of the bounding box\n",
    "# h is the height of the bounding box\n",
    "x, y, w, h = cv2.boundingRect(contours[0])\n",
    "cv2.rectangle(first_contour,(x,y), (x+w,y+h), (255,0,0), 5)\n",
    "cv2.imshow('First contour with bounding box', first_contour)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Draw a bounding box around all contours\n",
    "for c in contours:\n",
    "  x, y, w, h = cv2.boundingRect(c)\n",
    " \n",
    "    # Make sure contour area is large enough\n",
    "  if (cv2.contourArea(c)) > 10:\n",
    "    cv2.rectangle(with_contours,(x,y), (x+w,y+h), (255,0,0), 5)\n",
    "         \n",
    "cv2.imshow('All contours with bounding box', with_contours)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee73d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"s1.jpg\")\n",
    "\n",
    "# convert img to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# do adaptive threshold on gray image\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 101, 3)\n",
    "\n",
    "# apply morphology open then close\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "blob = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "blob = cv2.morphologyEx(blob, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# invert blob\n",
    "blob = (255 - blob)\n",
    "\n",
    "# Get contours\n",
    "cnts = cv2.findContours(blob, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "big_contour = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# test blob size\n",
    "blob_area_thresh = 100\n",
    "blob_area = cv2.contourArea(big_contour)\n",
    "if blob_area < blob_area_thresh:\n",
    "    print(\"Blob Is Too Small\")\n",
    "\n",
    "# draw contour\n",
    "result = img.copy()\n",
    "cv2.drawContours(result, [big_contour], -1, (0,0,255), 1)\n",
    "\n",
    "# write results to disk\n",
    "cv2.imwrite(\"doco3_threshold.jpg\", thresh)\n",
    "cv2.imwrite(\"doco3_blob.jpg\", blob)\n",
    "cv2.imwrite(\"doco3_contour.jpg\", result)\n",
    "\n",
    "# display it\n",
    "cv2.imshow(\"IMAGE\", img)\n",
    "cv2.imshow(\"THRESHOLD\", thresh)\n",
    "cv2.imshow(\"BLOB\", blob)\n",
    "cv2.imshow(\"RESULT\", result)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ca210",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23987072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def segment_image(file):\n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    lower_green = np.array([25,0,20])\n",
    "    upper_green = np.array([100,255,255])\n",
    "    mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "    lower_brown = np.array([10,0,10])\n",
    "    upper_brown = np.array([30,255,255])\n",
    "    disease_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    disease_result = cv2.bitwise_and(img, img, mask=disease_mask)\n",
    "    final_mask = mask + disease_mask\n",
    "    final_result = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "#     output_path= os.path.basename(os.path.dirname(file))+'/'+os.path.basename(\"seg.jpg\")\n",
    "    cv2.imwrite(\"o.jpg\",final_result)\n",
    "    \n",
    "segment_image(\"x.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00eb6d4",
   "metadata": {},
   "source": [
    "# Mask Infected Region\n",
    "https://stackoverflow.com/questions/67448621/how-to-calculate-the-percentage-of-infected-area-on-leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93bb61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img =  cv2.imread('o.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# find the green color \n",
    "mask_green = cv2.inRange(hsv, (36, 0, 0), (86,255,255))\n",
    "# find the brown color\n",
    "mask_brown = cv2.inRange(hsv, (8, 60, 20), (30, 255, 255))\n",
    "# find the yellow color in the leaf\n",
    "mask_yellow = cv2.inRange(hsv, (14, 39, 64), (40, 255, 255))\n",
    "\n",
    "# find any of the three colors(green or brown or yellow) in the image\n",
    "#mask = cv2.bitwise_or(mask_green, mask_brown)\n",
    "#mask = cv2.bitwise_or(mask, mask_yellow)\n",
    "mask = cv2.bitwise_not(mask_green)\n",
    "\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_not(img, img, mask= mask)\n",
    "\n",
    "cv2.imshow(\"final image\", res)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Display the grayscale image\n",
    "# cv2.imshow('Gray image', gray)  \n",
    "cv2.waitKey(0) # Wait for keypress to continue\n",
    "cv2.destroyAllWindows() # Close windows\n",
    " \n",
    "# Convert the grayscale image to binary\n",
    "ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "# Display the binary image\n",
    "# cv2.imshow('Binary image', binary)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e66edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 0.0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(mask_brown))\n",
    "sum(sum(mask_green))\n",
    "sum(sum(mask_yellow))\n",
    "\n",
    "brown = sum(sum(mask_brown))\n",
    "green = sum(sum(mask_green))\n",
    "yellow = sum(sum(mask_yellow))\n",
    "total = brown + green + yellow\n",
    "percentHealthy = green / total\n",
    "percentDiseased = (brown + yellow) / total\n",
    "(percentHealthy*100, percentDiseased*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d24eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########################################\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "\n",
    "def show_images(images):\n",
    "    for (i, img) in enumerate(images):\n",
    "        cv2.imshow('image_' + str(i), img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "\n",
    "edged = cv2.Canny(blur, 50, 100)\n",
    "edged = cv2.dilate(edged, None, iterations=1)\n",
    "edged = cv2.erode(edged, None, iterations=1)\n",
    "\n",
    "# show_images([blur, edged])\n",
    "\n",
    "# Find contours\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "i=0\n",
    "for contour in cnts[0]:\n",
    "    if cv2.contourArea(contour) > 100:\n",
    "        [X, Y, W, H] = cv2.boundingRect(contour)\n",
    "        #box=cv2.rectangle(resized, (X, Y), (X + W, Y + H), (0,0,255), 2)\n",
    "        cropped_image = img[Y:Y+H, X:X+W]\n",
    "        #print([X,Y,W,H])\n",
    "        cv2.imwrite(str(i) + \".jpg\", cropped_image )\n",
    "        i = i+1\n",
    "\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "# Sort contours from left to right as leftmost contour is reference object\n",
    "\n",
    "(cnts, _) = contours.sort_contours(cnts)\n",
    "\n",
    "# Remove contours which are not large enough\n",
    "\n",
    "cnts = [x for x in cnts if cv2.contourArea(x) > 100]\n",
    "\n",
    "# cv2.drawContours(image, cnts, -1, (0,255,0), 3)\n",
    "\n",
    "#show_images([image, edged])\n",
    "# print(len(cnts))\n",
    "\n",
    "# Reference object dimensions\n",
    "# Here for reference I have used a 2cm x 2cm square\n",
    "\n",
    "ref_object = cnts[0]\n",
    "box = cv2.minAreaRect(ref_object)\n",
    "box = cv2.boxPoints(box)\n",
    "box = np.array(box, dtype='int')\n",
    "box = perspective.order_points(box)\n",
    "(tl, tr, br, bl) = box\n",
    "dist_in_pixel = euclidean(tl, tr)\n",
    "dist_in_cm = 5\n",
    "pixel_per_cm = dist_in_pixel / dist_in_cm\n",
    "\n",
    "# Draw remaining contours\n",
    "j=0;\n",
    "for cnt in cnts:\n",
    "    \n",
    "        \n",
    "    box = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(box)\n",
    "    box = np.array(box, dtype='int')\n",
    "    box = perspective.order_points(box)\n",
    "    (tl, tr, br, bl) = box\n",
    "    cv2.drawContours(img, [box.astype('int')], -1, (0, 0, 255), 2)\n",
    "    mid_pt_horizontal = (tl[0] + int(abs(tr[0] - tl[0]) / 2), tl[1]\n",
    "                         + int(abs(tr[1] - tl[1]) / 2))\n",
    "    mid_pt_verticle = (tr[0] + int(abs(tr[0] - br[0]) / 2), tr[1]\n",
    "                       + int(abs(tr[1] - br[1]) / 2))\n",
    "    wid = euclidean(tl, tr) / pixel_per_cm\n",
    "    ht = euclidean(tr, br) / pixel_per_cm\n",
    "    \n",
    "#     cv2.putText(\n",
    "#         img,\n",
    "#         '{:.1f}cm'.format(wid),\n",
    "#         (int(mid_pt_horizontal[0] - 15), int(mid_pt_horizontal[1]\n",
    "#          - 10)),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#         0.5,\n",
    "#         (255, 255, 0),\n",
    "#         2,\n",
    "#         )\n",
    "#     cv2.putText(\n",
    "#         img,\n",
    "#         '{:.1f}cm'.format(ht),\n",
    "#         (int(mid_pt_verticle[0] + 10), int(mid_pt_verticle[1])),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#         0.5,\n",
    "#         (255, 255, 0),\n",
    "#         2,\n",
    "#         )\n",
    "    if wid <= 5 or ht <= 5:            \n",
    "        [X, Y, W, H] = cv2.boundingRect(cnt)\n",
    "        #box=cv2.rectangle(resized, (X, Y), (X + W, Y + H), (0,0,255), 2)\n",
    "        cropped_image = img[Y:Y+H, X:X+W]\n",
    "        #print([X,Y,W,H])\n",
    "#         cv2.imwrite( \"small\" + str(j) + \".jpg\", cropped_image )\n",
    "        j = j+1\n",
    "            \n",
    "        print(\"small\" , wid , ht)\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            'small',\n",
    "            (200,200),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            2,\n",
    "            )\n",
    "\n",
    "    elif (wid >= 5 and wid <7) or (ht >= 5 and ht <7):\n",
    "        [X, Y, W, H] = cv2.boundingRect(cnt)\n",
    "        #box=cv2.rectangle(resized, (X, Y), (X + W, Y + H), (0,0,255), 2)\n",
    "        cropped_image = img[Y:Y+H, X:X+W]\n",
    "        #print([X,Y,W,H])\n",
    "#         cv2.imwrite( \"medium\" + str(j) + \".jpg\", cropped_image )\n",
    "        j = j+1\n",
    "        \n",
    "        print(\"medium\" , wid, ht)\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            'medium',\n",
    "            (100,200),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            2,\n",
    "            )\n",
    "    elif wid >= 6 or ht >= 6:\n",
    "        [X, Y, W, H] = cv2.boundingRect(cnt)\n",
    "        #box=cv2.rectangle(resized, (X, Y), (X + W, Y + H), (0,0,255), 2)\n",
    "        cropped_image = img[Y:Y+H, X:X+W]\n",
    "        #print([X,Y,W,H])\n",
    "#         cv2.imwrite( \"large\" + str(j) + \".jpg\", cropped_image )\n",
    "        j = j+1\n",
    "        \n",
    "        cv2.putText(\n",
    "            img,\n",
    "            'large',\n",
    "            (200,300),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            2,\n",
    "            )\n",
    "\n",
    "show_images([img])\n",
    "\n",
    "##########################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
